This is a very interesting overview of state of AI in 2020 :
https://www.stateof.ai/

It covers several dimensions : research, talent, industry, politics, and makes predictions about next year.

Among many other things, what I've found interesting in particular :

1. Research
⋅⋅* AI research is less open than you think: Only 15% of papers publish their code
⋅⋅* Facebook’s PyTorch is fast outpacing Google’s TensorFlow in research papers, which tends to be a leading indicator of production use down the line
⋅⋅* PyTorch is also more popular than TensorFlow in paper implementations on GitHub
⋅⋅* Huge models, large companies and massive training costs dominate the hottest area of AI today, Natural Language Processing
  => GPT 3 gigantic model with 175B parameters which is 10x more than the second biggest one (Turing-NLG)
  => It's not written in the document, but I think that's a shame that GPT 3 is still a closed model, not released publicly by Open AI (why have they "Open" in their name then ?)
  
⋅⋅* We’re rapidly approaching outrageous computational, economic, and environmental costs to gain incrementally smaller improvements in model performance
⋅⋅* Without major new research breakthroughs, dropping the ImageNet error rate from 11.5% to 1% would require over one hundred billion billion dollars! Many practitioners feel that progress in mature areas of ML is stagnant.
⋅⋅* GPT-3, T5, BART are driving a drastic improvement in the performance of transformer models for text-to-text tasks like translation, summarization, text generation, text to code.
  => Check huggingface library for NLP
  
 Biology is experiencing its “AI moment”: From medical imaging, genetics, proteomics, chemistry to drug discovery.
. Graph neural networks: Solving problems by making use of 3D input data

. COVID-19: Analyzing symptoms from over 4 million contributors detects novel disease symptom ahead of public health community and could inform diagnosis without tests
. Drug discovery goes open source to tackle COVID-19. This is a rare example of where AI is being actively used on a clearly-defined problem that’s part of the COVID-19 response. 
. OpenMined, the leading open-source community for privacy-preserving ML, demonstrates  the first open-source federated learning platform for web, mobile, server, and IoT

2. Talent
. The Great Brain Drain: AI professors depart US universities for technology companies
. Google, DeepMind, Amazon, Microsoft have hired 52 tenured and tenure-track professors from US Universities between 2004 and 2018.
. The loss of AI professors seems to matter: Departures correlate with reduced graduate entrepreneurship across 69 US universities
. 29% of authors with papers accepted at NeurIPS 2019 earned their undergraduate degree in China.
. But after leaving university in China, 54% of graduates who go on to publish at NeurIPS move to the USA !
. The US is an incredibly strong talent retainer post-PhD
. The majority of top AI researchers working in the US were not trained in America
. Analysis of Indeed.com US data shows almost 3x more job postings than job views for AI-related roles. Job postings grew 12x faster than job viewings in the last from late 2016 to late 2018. 
.  Public job postings on LinkedIn that mention a deep learning framework were on a strong 2020 ramp up but took a hit due to COVID-19 since February 2020

3. Industry
. Driverless cars are still not so driverless: Only 3 of 66 companies with AV testing permits in California are allowed to test without safety drivers since 2018
   => 3 companies driving *without* safety driver at all : that's still something !
. Use of ML in self-driving is still mostly limited to perception with large parts of stack hand-engineered.
. Much of today’s ML in self-driving systems focus only on understanding what is around the vehicle.
. What the self-driving car should do is mostly hand-engineered making development difficult and slow.
. Recently, both Waymo, Uber and Lyft demonstrated new techniques of imitation learning and inverse **reinforcement learning** instead of hand-written rules.
. 6x faster training time for the image classification model EfficientNet-B4 on the **Graphcore** M2000 vs. **NVIDIA** DGX-A100 translates to an 12x cost advantage
. NLP :     1,000+ companies are using Hugging Face’s Transformers library in production: 5M pip installs, 2,500+ community transformer models trained in over 164 languages by 430 contributors.

4. Politics
. Facial recognition is remarkably common around the world
. GPT-3, like GPT-2, still outputs biased predictions when prompted with topics of religion
. From DeepMind to U.S. Army Research Lab, AI research agendas start to overlap
. The U.S. continues to make major investments to implement military AI systems
. Semiconductors amplify the geopolitical significance of Taiwan and particularly TSMC (leading semiconductor company in Taiwan)
. TSMC grows in importance to the US semiconductor strategy.
. China hires over 100 TSMC engineers in push to close gap in semiconductor capabilities
. Company acquisition in semiconductors has been highly politicised. The vast majority of acquisitions have been blocked.:
.. Example : December 2016: US and Germany block $723M bid by China’s Fujian Grand Chip Investment Fund (China) for Aixtron.
.. Example : July 2018: China blocks Qualcomm’s $44B bid for NXP (Netherlands).
. AI Nationalism: Governments increasingly plan to scrutinise acquisitions of AI companies
. The likely sale of Arm to NVIDIA is questioned by many, including its founder
. China moves to create “national new generation AI innovation and development pilot zones”.
. AI pilot zones are encouraged to “carry out AI based policy experiments” and “carry out AI based social experiments”. 













